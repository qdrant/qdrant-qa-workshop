{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Vector search\n",
    "\n",
    "At scale nobody performs an original kNN for the vector similarity. It just doesn't scale well enough if you have thousands or millions of vectors. There is a lot going on in the area of **Approximate Nearest Neighbours**. There is plenty of available *vector databases* that implements the process of finding similar vectors as a service, and [Qdrant](https://qdrant.tech) is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T13:45:34.404004Z",
     "start_time": "2022-11-02T13:45:32.408030Z"
    }
   },
   "outputs": [],
   "source": [
    "!cd .. && docker-compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:31.900223Z",
     "start_time": "2022-11-02T14:17:30.272843Z"
    }
   },
   "outputs": [],
   "source": [
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:32.010782Z",
     "start_time": "2022-11-02T14:17:31.903465Z"
    }
   },
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\", port=6333, timeout=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:32.034808Z",
     "start_time": "2022-11-02T14:17:32.013620Z"
    }
   },
   "outputs": [],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start with putting the data into the Qdrant collection, so it might be queried effectively after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:33.195084Z",
     "start_time": "2022-11-02T14:17:32.040746Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:38.051540Z",
     "start_time": "2022-11-02T14:17:33.198501Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_qa_dataset = load_dataset(\"tweet_qa\")\n",
    "train_df = pd.DataFrame(tweet_qa_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we're going to use a pretrained model to create those vectors. And we're going to vectorize the answers (full tweets) to put them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T15:35:03.329279Z",
     "start_time": "2022-11-02T15:35:03.322119Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T15:35:03.945067Z",
     "start_time": "2022-11-02T15:35:03.532535Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:43.337599Z",
     "start_time": "2022-11-02T14:17:43.333531Z"
    }
   },
   "outputs": [],
   "source": [
    "from qdrant_client.http import models as rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:17:44.086623Z",
     "start_time": "2022-11-02T14:17:43.340740Z"
    }
   },
   "outputs": [],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"tweets-qa\",\n",
    "    vectors_config=rest.VectorParams(\n",
    "        size=embedder[0].get_word_embedding_dimension(),\n",
    "        distance=rest.Distance.COSINE,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:20:23.717255Z",
     "start_time": "2022-11-02T14:17:44.089985Z"
    }
   },
   "outputs": [],
   "source": [
    "answer_embeddings = embedder.encode(train_df[\"Tweet\"])\n",
    "client.upload_collection(\n",
    "    collection_name=\"tweets-qa\",\n",
    "    vectors=answer_embeddings.tolist(),\n",
    "    payload=[{\"qid\": qid} for qid in train_df[\"qid\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:20:23.729175Z",
     "start_time": "2022-11-02T14:20:23.720343Z"
    }
   },
   "outputs": [],
   "source": [
    "client.get_collection(\"tweets-qa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the next step is to use the question embeddings to find the most relevant tweet for each of them. Since we know the proper one, we can easily calculate the embeddings quality using **top-k-accuracy** measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:20:44.031775Z",
     "start_time": "2022-11-02T14:20:23.732104Z"
    }
   },
   "outputs": [],
   "source": [
    "question_embeddings = embedder.encode(train_df[\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:20:44.041050Z",
     "start_time": "2022-11-02T14:20:44.034575Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def top_k_accuracy(k: int):\n",
    "    found_in_top = 0\n",
    "    for target_qid, question_embedding in zip(train_df[\"qid\"],\n",
    "                                              question_embeddings):\n",
    "        response = client.search(\n",
    "            collection_name=\"tweets-qa\",\n",
    "            query_vector=question_embedding,\n",
    "            limit=k,\n",
    "            with_payload=True,\n",
    "        )\n",
    "        top_qids = [point.payload.get(\"qid\") for point in response]\n",
    "        if target_qid in top_qids:\n",
    "            found_in_top += 1\n",
    "    return found_in_top / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:22:46.633961Z",
     "start_time": "2022-11-02T14:20:44.043688Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k_accuracy(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:25:09.144766Z",
     "start_time": "2022-11-02T14:22:46.640308Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k_accuracy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
