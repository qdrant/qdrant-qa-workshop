{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data exploration\n",
    "\n",
    "## The problem\n",
    "\n",
    "We're going to implement a Question-Answering system, using a publicly available dataset - [TweetQA](https://tweetqa.github.io/). The dataset consists of tweets and corresponding question they could be possibly answering. All annotated by people, using Amazon Mechanical Turk. **Our target system is going to find the most relevant tweets, given question.** We're going to be using only Open Source tools to first of all, use an existing pretrained model, and then further fine-tune it, so it works better in our domain.\n",
    "\n",
    "## TweetQA\n",
    "\n",
    "The dataset is split in train, validation and test set. The train set cointains 10692 examples, the validation set 1086 and the test set 1979 examples. It comes from the following paper:\n",
    "\n",
    "*TweetQA: A Social Media Focused Question Answering Dataset, Xiong, Wenhan and Wu, Jiawei and Wang, Hong and Kulkarni, Vivek and Yu, Mo and Guo, Xiaoxiao and Chang, Shiyu and Wang, William Yang, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2019*\n",
    "\n",
    "> With social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effectiveness of many applications that rely on real-time knowledge. While previous question answering (QA) datasets have concentrated on formal text like news and Wikipedia, we present the first large-scale dataset for QA over social media data. To make the tweets are meaningful and contain interesting information, we gather tweets used by journalists to write news articles. We then ask human annotators to write questions and answers upon these tweets. Unlike other QA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. The task requires model to read a short tweet and a question and outputs a text phrase (does not need to be in the tweet) as the answer.\n",
    "\n",
    "The dataset is available in HuggingFace datasets hub, so we'll download it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_qa_dataset = load_dataset(\"tweet_qa\")\n",
    "tweet_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(tweet_qa_dataset[\"train\"])\n",
    "train_df.sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more complex problem is not only to select the tweet that answers the question, but also a specific part of the message that is a specific response to that question. **We're trying to solve the easier problem first, so our system should return a whole tweet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested approach\n",
    "\n",
    "### Neural embeddings\n",
    "\n",
    "Neural embeddings are numerical representations of the input data, generated by Deep Learning Neural Networks. There are plenty of pretrained models available.\n",
    "\n",
    "#### Bi-encoders vs cross-encoders\n",
    "\n",
    "![](images/Bi_vs_Cross-Encoder.png)\n",
    "\n",
    "Source: https://www.sbert.net/examples/applications/cross-encoder/README.html\n",
    "\n",
    "With bi-encoders we're actually trying to encode the question and answer with the same model, so their representations are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
